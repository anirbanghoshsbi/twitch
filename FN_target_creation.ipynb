{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from joblib import load\n",
    "\n",
    "dtype_dict = load('dtype_dict1.joblib') #from the Feather Format tutorial series - save RAM!\n",
    "train_datalink = 'https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz'\n",
    "df = pd.read_csv(train_datalink, dtype=dtype_dict)\n",
    "features = [c for c in df if c.startswith(\"feature\")]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def _neutralize(df, columns, by, proportion=1.0):\n",
    "    scores = df[columns]\n",
    "    exposures = df[by].values\n",
    "    scores = scores - proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n",
    "    return scores / scores.std()\n",
    "def _normalize(df):\n",
    "    X = (df.rank(method=\"first\") - 0.5) / len(df)\n",
    "    return scipy.stats.norm.ppf(X)\n",
    "def normalize_and_neutralize(df, columns, by, proportion=1.0):\n",
    "    # Convert the scores to a normal distribution\n",
    "    df[columns] = _normalize(df[columns])\n",
    "    df[columns] = _neutralize(df, columns, by, proportion)\n",
    "    return df[columns]\n",
    "\n",
    "df['neutralized_target'] = df.groupby(\"era\").apply(lambda x: normalize_and_neutralize(x, [\"target\"], features, 0.8)) #set your proportion to the desired amount of feature neutralization you want\n",
    "scaler = MinMaxScaler()\n",
    "df['neutralized_target'] = scaler.fit_transform(df[['neutralized_target']]) # transform back to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    501808.000000\n",
       "mean          0.491187\n",
       "std           0.116901\n",
       "min           0.000000\n",
       "25%           0.412584\n",
       "50%           0.491255\n",
       "75%           0.569846\n",
       "max           1.000000\n",
       "Name: neutralized_target, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['neutralized_target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.feather as feather\n",
    "\n",
    "feather.write_feather(df, 'df_neut_training_compressed_nomi80.feather', compression='lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
